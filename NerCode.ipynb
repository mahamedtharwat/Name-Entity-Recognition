{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pos_tag</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pedestrians</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April Sosa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keith Golden</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>Motaz</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14176</th>\n",
       "      <td>Ahmed</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177</th>\n",
       "      <td>Amar</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14178</th>\n",
       "      <td>Moaz</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>Amr</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14180 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word Pos_tag     Tag\n",
       "Index                              \n",
       "0                in      IN       O\n",
       "1                in      IN       O\n",
       "2       pedestrians     NNP       O\n",
       "3        April Sosa     NNP  PERSON\n",
       "4      Keith Golden     NNP  PERSON\n",
       "...             ...     ...     ...\n",
       "14175         Motaz     NNP  PERSON\n",
       "14176         Ahmed     NNP  PERSON\n",
       "14177          Amar     NNP  PERSON\n",
       "14178          Moaz     NNP  PERSON\n",
       "14179           Amr     NNP  PERSON\n",
       "\n",
       "[14180 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14180 entries, 0 to 14179\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Word     14180 non-null  object\n",
      " 1   Pos_tag  14180 non-null  object\n",
      " 2   Tag      14180 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 443.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14180 entries, 0 to 14179\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Word     14180 non-null  object\n",
      " 1   Pos_tag  14180 non-null  object\n",
      " 2   Tag      14180 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 443.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Duplicates Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>7311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Duplicates Rows\n",
       "                       7311"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Number of Duplicates Rows\":data.duplicated().sum()},index=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Duplicates Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Duplicates Rows\n",
       "                          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Number of Duplicates Rows\":data.duplicated().sum()},index=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6869, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'PERSON', 'DATE', 'P-NUMBER', 'CARDINAL', 'COMPANY', 'ORG',\n",
       "       'COLOR', 'Org', 'CITY', 'COUNTRY'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\AppData\\Local\\Temp\\ipykernel_11944\\4199561983.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Tag_Encoding'] = data['Tag'].factorize()[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index\n",
       "0        0\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "5        0\n",
       "        ..\n",
       "14175    1\n",
       "14176    1\n",
       "14177    1\n",
       "14178    1\n",
       "14179    1\n",
       "Name: Tag_Encoding, Length: 6869, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag_Encoding'] = data['Tag'].factorize()[0]\n",
    "data['Tag_Encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag_Encoding'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tag_label={'O':0, 'PERSON':1, 'DATE':2, 'P-NUMBER':3, 'CARDINAL':4, 'COMPANY':5, 'ORG':6,\n",
    "       'COLOR':7, 'Org':8, 'CITY':9, 'COUNTRY':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'PERSON': 1,\n",
       " 'DATE': 2,\n",
       " 'P-NUMBER': 3,\n",
       " 'CARDINAL': 4,\n",
       " 'COMPANY': 5,\n",
       " 'ORG': 6,\n",
       " 'COLOR': 7,\n",
       " 'Org': 8,\n",
       " 'CITY': 9,\n",
       " 'COUNTRY': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tag_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Tag'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.Tag.explode().to_frame().reset_index(drop=True)\n",
    "dfc = data.groupby('Tag').Tag.count().reset_index(name = 'Count').sort_values(['Count'],ascending=False)\n",
    "dfc.plot.bar(x='Tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word            object\n",
       "Pos_tag         object\n",
       "Tag             object\n",
       "Tag_Encoding     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['in', 'pedestrians', 'April Sosa', ..., 'Amar', 'Moaz', 'Amr'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"Word\", \"Pos_tag\"]]\n",
    "Y = data[\"Tag\"]\n",
    "\n",
    "word_vectorizer = CountVectorizer()\n",
    "X_words = word_vectorizer.fit_transform(X[\"Word\"])\n",
    "\n",
    "pos_vectorizer = CountVectorizer()\n",
    "X_pos = pos_vectorizer.fit_transform(X[\"Pos_tag\"])\n",
    "X_combined = pd.concat(\n",
    "    [pd.DataFrame(X_words.toarray()), pd.DataFrame(X_pos.toarray())], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_combined, Y, test_size=0.3,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = {\"SVC\": SVC(kernel=\"linear\"), \"LogisticRegression\": LogisticRegression(), \"RidgeClassifierCV\": RidgeClassifierCV(alphas=[0.1,1,10]),\n",
    "         \"SGDClassifier\": SGDClassifier(), \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=150 \n",
    "                                                                                            ,criterion='entropy'),\n",
    "              \n",
    "         \"RandomForestClassifier\": RandomForestClassifier(n_estimators=100,\n",
    "                                                          max_depth=150,\n",
    "                                                          criterion='entropy', \n",
    "                                                          n_jobs=2),\n",
    "         \"mlp_Classifier\":MLPClassifier(learning_rate_init=0.0005, max_iter=300)}\n",
    "def BuildModel(training_padded, training_labels, testing_padded, testing_labels, model):\n",
    "  dic_test_evluation_metrics={}\n",
    "  dic_train_evluation_metrics={}\n",
    "  dic_models={}\n",
    "\n",
    "  for model_name in model:\n",
    "      current_model = model[model_name]\n",
    "      current_model.fit(x_train, y_train)\n",
    "      dic_models[model_name] = current_model\n",
    "\n",
    "      y_test_pre = current_model.predict(x_test)\n",
    "      y_train_pre = current_model.predict(x_train)\n",
    "\n",
    "      dic_test_evluation_metrics[model_name] = dic_evaluation_test = {\n",
    "          \"Model_name\": model_name,\n",
    "          \"accuracy\": round(accuracy_score(y_test, y_test_pre) * 100, 3),\n",
    "          \"precision\": round(precision_score(y_test, y_test_pre, average='macro') * 100, 3),\n",
    "          \"recall_score\": round(recall_score(y_test, y_test_pre, average='macro') * 100, 3),\n",
    "          \"f1_score\": round(f1_score(y_test, y_test_pre, average='macro') * 100, 3),\n",
    "          \"confusion_matrix\": confusion_matrix(y_test, y_test_pre)}\n",
    "      \n",
    "      \n",
    "      dic_train_evluation_metrics[model_name] = dic_evaluation_train = {\n",
    "          \"Model_name\": model_name,\n",
    "          \"accuracy\":  round(accuracy_score(y_train, y_train_pre)* 100, 3),\n",
    "          \"precision\": round(precision_score(y_train, y_train_pre, average='macro')* 100, 3),\n",
    "          \"recall_score\":  round(recall_score(y_train, y_train_pre, average='macro')* 100, 3),\n",
    "          \"f1_score\":  round(f1_score(y_train, y_train_pre, average='macro')* 100, 3),\n",
    "          \"confusion_matrix\": confusion_matrix(y_train, y_train_pre)}\n",
    "  return dic_test_evluation_metrics, dic_train_evluation_metrics, dic_models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dic_test_evluation_metrics, dic_train_evluation_metrics, dic_models = BuildModel(x_train, y_train, x_test, y_test, Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>76.274</td>\n",
       "      <td>72.605</td>\n",
       "      <td>49.141</td>\n",
       "      <td>52.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>73.217</td>\n",
       "      <td>76.654</td>\n",
       "      <td>44.683</td>\n",
       "      <td>46.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>78.651</td>\n",
       "      <td>70.925</td>\n",
       "      <td>50.134</td>\n",
       "      <td>52.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>78.991</td>\n",
       "      <td>67.452</td>\n",
       "      <td>51.337</td>\n",
       "      <td>53.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>67.880</td>\n",
       "      <td>70.847</td>\n",
       "      <td>41.072</td>\n",
       "      <td>43.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>67.103</td>\n",
       "      <td>73.612</td>\n",
       "      <td>40.878</td>\n",
       "      <td>42.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlp_Classifier</td>\n",
       "      <td>80.107</td>\n",
       "      <td>62.511</td>\n",
       "      <td>50.769</td>\n",
       "      <td>52.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_name  accuracy  precision  recall_score  f1_score\n",
       "0                     SVC    76.274     72.605        49.141    52.201\n",
       "1      LogisticRegression    73.217     76.654        44.683    46.681\n",
       "2       RidgeClassifierCV    78.651     70.925        50.134    52.417\n",
       "3           SGDClassifier    78.991     67.452        51.337    53.409\n",
       "4  DecisionTreeClassifier    67.880     70.847        41.072    43.458\n",
       "5  RandomForestClassifier    67.103     73.612        40.878    42.328\n",
       "6          mlp_Classifier    80.107     62.511        50.769    52.054"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic_test_evluation_metrics.values()).drop(['confusion_matrix'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.314</td>\n",
       "      <td>98.747</td>\n",
       "      <td>99.174</td>\n",
       "      <td>98.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>86.314</td>\n",
       "      <td>76.872</td>\n",
       "      <td>52.025</td>\n",
       "      <td>55.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>99.334</td>\n",
       "      <td>99.042</td>\n",
       "      <td>99.372</td>\n",
       "      <td>99.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>99.210</td>\n",
       "      <td>98.130</td>\n",
       "      <td>99.080</td>\n",
       "      <td>98.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>77.704</td>\n",
       "      <td>95.009</td>\n",
       "      <td>58.170</td>\n",
       "      <td>62.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>73.461</td>\n",
       "      <td>75.941</td>\n",
       "      <td>45.199</td>\n",
       "      <td>49.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlp_Classifier</td>\n",
       "      <td>99.563</td>\n",
       "      <td>99.610</td>\n",
       "      <td>99.296</td>\n",
       "      <td>99.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_name  accuracy  precision  recall_score  f1_score\n",
       "0                     SVC    99.314     98.747        99.174    98.953\n",
       "1      LogisticRegression    86.314     76.872        52.025    55.332\n",
       "2       RidgeClassifierCV    99.334     99.042        99.372    99.199\n",
       "3           SGDClassifier    99.210     98.130        99.080    98.554\n",
       "4  DecisionTreeClassifier    77.704     95.009        58.170    62.878\n",
       "5  RandomForestClassifier    73.461     75.941        45.199    49.417\n",
       "6          mlp_Classifier    99.563     99.610        99.296    99.450"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic_train_evluation_metrics.values()).drop('confusion_matrix', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"The fact that Henry Armstrong was buried did not seem to him to prove that he was dead: he had always been a hard man to convince. That \n",
    "he really was buried, the testimony of his senses compelled him to admit. His posture -- flat upon his back, with his hands crossed upon his \n",
    "stomach and tied with something that he easily broke without profitably altering the situation -- the strict confinement of his entire person, the \n",
    "black darkness and profound silence, made a body of evidence impossible to controvert and he accepted it without cavil.\n",
    "But dead -- no; he was only very, very ill. He had, withal, the invalid's apathy and did not greatly concern himself about the uncommon fate that \n",
    "had been allotted to him. No philosopher was he -- just a plain, commonplace person gifted, for the time being, with a pathological \n",
    "indifference: the organ that he feared consequences with was torpid. So, with no particular apprehension for his immediate future, he fell \n",
    "asleep and all was peace with Henry Armstrong.\n",
    "But something was going on overhead. It was a dark summer night, shot through with infrequent shimmers of lightning silently firing a cloud \n",
    "lying low in the west and portending a storm. These brief, stammering illuminations brought out with ghastly distinctness the monuments and \n",
    "headstones of the cemetery and seemed to set them dancing. It was not a night in which any credible witness was likely to be straying about a \n",
    "cemetery, so the three men who were there, digging into the grave of Henry Armstrong, felt reasonably secure.\n",
    "Two of them were young students from a medical college a few miles away; the third was a gigantic negro known as Jess. For many years \n",
    "Jess had been employed about the cemetery as a man-of-all-work and it was his favourite pleasantry that he knew 'every soul in the place.' \n",
    "From the nature of what he was now doing it was inferable that the place was not so populous as its register may have shown it to be.\n",
    "Outside the wall, at the part of the grounds farthest from the public road, were a horse and a light wagon, waiting.\n",
    "The work of excavation was not difficult: the earth with which the grave had been loosely filled a few hours before offered little resistance and \n",
    "was soon thrown out. Removal of the casket from its box was less easy, but it was taken out, for it was a perquisite of Jess, who carefully \n",
    "unscrewed the cover and laid it aside, exposing the body in black trousers and white shirt. At that instant the air sprang to flame, a cracking \n",
    "shock of thunder shook the stunned world and Henry Armstrong tranquilly sat up. With inarticulate cries the men fled in terror, each in a \n",
    "different direction. For nothing on earth could two of them have been persuaded to return. But Jess was of another breed.\n",
    "In the grey of the morning the two students, pallid and haggard from anxiety and with the terror of their adventure still beating tumultuously in \n",
    "their blood, met at the medical college.\n",
    "'You saw it?' cried one.\n",
    "'God! yes -- what are we to do?'\n",
    "They went around to the rear of the building, where they saw a horse, attached to a light wagon, hitched to a gatepost near the door of the \n",
    "dissecting-room. Mechanically they entered the room. On a bench in the obscurity sat the negro Jess. He rose, grinning, all eyes and teeth.\n",
    "'I'm waiting for my pay,' he said.\n",
    "Stretched naked on a long table lay the body of Henry Armstrong, the head defiled with blood and clay from a blow with a spade.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'Henry',\n",
       "  'Armstrong',\n",
       "  'was',\n",
       "  'buried',\n",
       "  'did',\n",
       "  'not',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'him',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'that',\n",
       "  'he',\n",
       "  'was',\n",
       "  'dead',\n",
       "  ':',\n",
       "  'he',\n",
       "  'had',\n",
       "  'always',\n",
       "  'been',\n",
       "  'a',\n",
       "  'hard',\n",
       "  'man',\n",
       "  'to',\n",
       "  'convince',\n",
       "  '.'],\n",
       " ['That',\n",
       "  'he',\n",
       "  'really',\n",
       "  'was',\n",
       "  'buried',\n",
       "  ',',\n",
       "  'the',\n",
       "  'testimony',\n",
       "  'of',\n",
       "  'his',\n",
       "  'senses',\n",
       "  'compelled',\n",
       "  'him',\n",
       "  'to',\n",
       "  'admit',\n",
       "  '.'],\n",
       " ['His',\n",
       "  'posture',\n",
       "  '--',\n",
       "  'flat',\n",
       "  'upon',\n",
       "  'his',\n",
       "  'back',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'hands',\n",
       "  'crossed',\n",
       "  'upon',\n",
       "  'his',\n",
       "  'stomach',\n",
       "  'and',\n",
       "  'tied',\n",
       "  'with',\n",
       "  'something',\n",
       "  'that',\n",
       "  'he',\n",
       "  'easily',\n",
       "  'broke',\n",
       "  'without',\n",
       "  'profitably',\n",
       "  'altering',\n",
       "  'the',\n",
       "  'situation',\n",
       "  '--',\n",
       "  'the',\n",
       "  'strict',\n",
       "  'confinement',\n",
       "  'of',\n",
       "  'his',\n",
       "  'entire',\n",
       "  'person',\n",
       "  ',',\n",
       "  'the',\n",
       "  'black',\n",
       "  'darkness',\n",
       "  'and',\n",
       "  'profound',\n",
       "  'silence',\n",
       "  ',',\n",
       "  'made',\n",
       "  'a',\n",
       "  'body',\n",
       "  'of',\n",
       "  'evidence',\n",
       "  'impossible',\n",
       "  'to',\n",
       "  'controvert',\n",
       "  'and',\n",
       "  'he',\n",
       "  'accepted',\n",
       "  'it',\n",
       "  'without',\n",
       "  'cavil',\n",
       "  '.'],\n",
       " ['But',\n",
       "  'dead',\n",
       "  '--',\n",
       "  'no',\n",
       "  ';',\n",
       "  'he',\n",
       "  'was',\n",
       "  'only',\n",
       "  'very',\n",
       "  ',',\n",
       "  'very',\n",
       "  'ill',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'had',\n",
       "  ',',\n",
       "  'withal',\n",
       "  ',',\n",
       "  'the',\n",
       "  'invalid',\n",
       "  \"'s\",\n",
       "  'apathy',\n",
       "  'and',\n",
       "  'did',\n",
       "  'not',\n",
       "  'greatly',\n",
       "  'concern',\n",
       "  'himself',\n",
       "  'about',\n",
       "  'the',\n",
       "  'uncommon',\n",
       "  'fate',\n",
       "  'that',\n",
       "  'had',\n",
       "  'been',\n",
       "  'allotted',\n",
       "  'to',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['No',\n",
       "  'philosopher',\n",
       "  'was',\n",
       "  'he',\n",
       "  '--',\n",
       "  'just',\n",
       "  'a',\n",
       "  'plain',\n",
       "  ',',\n",
       "  'commonplace',\n",
       "  'person',\n",
       "  'gifted',\n",
       "  ',',\n",
       "  'for',\n",
       "  'the',\n",
       "  'time',\n",
       "  'being',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'pathological',\n",
       "  'indifference',\n",
       "  ':',\n",
       "  'the',\n",
       "  'organ',\n",
       "  'that',\n",
       "  'he',\n",
       "  'feared',\n",
       "  'consequences',\n",
       "  'with',\n",
       "  'was',\n",
       "  'torpid',\n",
       "  '.'],\n",
       " ['So',\n",
       "  ',',\n",
       "  'with',\n",
       "  'no',\n",
       "  'particular',\n",
       "  'apprehension',\n",
       "  'for',\n",
       "  'his',\n",
       "  'immediate',\n",
       "  'future',\n",
       "  ',',\n",
       "  'he',\n",
       "  'fell',\n",
       "  'asleep',\n",
       "  'and',\n",
       "  'all',\n",
       "  'was',\n",
       "  'peace',\n",
       "  'with',\n",
       "  'Henry',\n",
       "  'Armstrong',\n",
       "  '.'],\n",
       " ['But', 'something', 'was', 'going', 'on', 'overhead', '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'a',\n",
       "  'dark',\n",
       "  'summer',\n",
       "  'night',\n",
       "  ',',\n",
       "  'shot',\n",
       "  'through',\n",
       "  'with',\n",
       "  'infrequent',\n",
       "  'shimmers',\n",
       "  'of',\n",
       "  'lightning',\n",
       "  'silently',\n",
       "  'firing',\n",
       "  'a',\n",
       "  'cloud',\n",
       "  'lying',\n",
       "  'low',\n",
       "  'in',\n",
       "  'the',\n",
       "  'west',\n",
       "  'and',\n",
       "  'portending',\n",
       "  'a',\n",
       "  'storm',\n",
       "  '.'],\n",
       " ['These',\n",
       "  'brief',\n",
       "  ',',\n",
       "  'stammering',\n",
       "  'illuminations',\n",
       "  'brought',\n",
       "  'out',\n",
       "  'with',\n",
       "  'ghastly',\n",
       "  'distinctness',\n",
       "  'the',\n",
       "  'monuments',\n",
       "  'and',\n",
       "  'headstones',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cemetery',\n",
       "  'and',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'set',\n",
       "  'them',\n",
       "  'dancing',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'not',\n",
       "  'a',\n",
       "  'night',\n",
       "  'in',\n",
       "  'which',\n",
       "  'any',\n",
       "  'credible',\n",
       "  'witness',\n",
       "  'was',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'be',\n",
       "  'straying',\n",
       "  'about',\n",
       "  'a',\n",
       "  'cemetery',\n",
       "  ',',\n",
       "  'so',\n",
       "  'the',\n",
       "  'three',\n",
       "  'men',\n",
       "  'who',\n",
       "  'were',\n",
       "  'there',\n",
       "  ',',\n",
       "  'digging',\n",
       "  'into',\n",
       "  'the',\n",
       "  'grave',\n",
       "  'of',\n",
       "  'Henry',\n",
       "  'Armstrong',\n",
       "  ',',\n",
       "  'felt',\n",
       "  'reasonably',\n",
       "  'secure',\n",
       "  '.'],\n",
       " ['Two',\n",
       "  'of',\n",
       "  'them',\n",
       "  'were',\n",
       "  'young',\n",
       "  'students',\n",
       "  'from',\n",
       "  'a',\n",
       "  'medical',\n",
       "  'college',\n",
       "  'a',\n",
       "  'few',\n",
       "  'miles',\n",
       "  'away',\n",
       "  ';',\n",
       "  'the',\n",
       "  'third',\n",
       "  'was',\n",
       "  'a',\n",
       "  'gigantic',\n",
       "  'negro',\n",
       "  'known',\n",
       "  'as',\n",
       "  'Jess',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'many',\n",
       "  'years',\n",
       "  'Jess',\n",
       "  'had',\n",
       "  'been',\n",
       "  'employed',\n",
       "  'about',\n",
       "  'the',\n",
       "  'cemetery',\n",
       "  'as',\n",
       "  'a',\n",
       "  'man-of-all-work',\n",
       "  'and',\n",
       "  'it',\n",
       "  'was',\n",
       "  'his',\n",
       "  'favourite',\n",
       "  'pleasantry',\n",
       "  'that',\n",
       "  'he',\n",
       "  'knew',\n",
       "  \"'every\",\n",
       "  'soul',\n",
       "  'in',\n",
       "  'the',\n",
       "  'place',\n",
       "  '.',\n",
       "  \"'\"],\n",
       " ['From',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'what',\n",
       "  'he',\n",
       "  'was',\n",
       "  'now',\n",
       "  'doing',\n",
       "  'it',\n",
       "  'was',\n",
       "  'inferable',\n",
       "  'that',\n",
       "  'the',\n",
       "  'place',\n",
       "  'was',\n",
       "  'not',\n",
       "  'so',\n",
       "  'populous',\n",
       "  'as',\n",
       "  'its',\n",
       "  'register',\n",
       "  'may',\n",
       "  'have',\n",
       "  'shown',\n",
       "  'it',\n",
       "  'to',\n",
       "  'be',\n",
       "  '.'],\n",
       " ['Outside',\n",
       "  'the',\n",
       "  'wall',\n",
       "  ',',\n",
       "  'at',\n",
       "  'the',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'grounds',\n",
       "  'farthest',\n",
       "  'from',\n",
       "  'the',\n",
       "  'public',\n",
       "  'road',\n",
       "  ',',\n",
       "  'were',\n",
       "  'a',\n",
       "  'horse',\n",
       "  'and',\n",
       "  'a',\n",
       "  'light',\n",
       "  'wagon',\n",
       "  ',',\n",
       "  'waiting',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'work',\n",
       "  'of',\n",
       "  'excavation',\n",
       "  'was',\n",
       "  'not',\n",
       "  'difficult',\n",
       "  ':',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'with',\n",
       "  'which',\n",
       "  'the',\n",
       "  'grave',\n",
       "  'had',\n",
       "  'been',\n",
       "  'loosely',\n",
       "  'filled',\n",
       "  'a',\n",
       "  'few',\n",
       "  'hours',\n",
       "  'before',\n",
       "  'offered',\n",
       "  'little',\n",
       "  'resistance',\n",
       "  'and',\n",
       "  'was',\n",
       "  'soon',\n",
       "  'thrown',\n",
       "  'out',\n",
       "  '.'],\n",
       " ['Removal',\n",
       "  'of',\n",
       "  'the',\n",
       "  'casket',\n",
       "  'from',\n",
       "  'its',\n",
       "  'box',\n",
       "  'was',\n",
       "  'less',\n",
       "  'easy',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'was',\n",
       "  'taken',\n",
       "  'out',\n",
       "  ',',\n",
       "  'for',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'perquisite',\n",
       "  'of',\n",
       "  'Jess',\n",
       "  ',',\n",
       "  'who',\n",
       "  'carefully',\n",
       "  'unscrewed',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'and',\n",
       "  'laid',\n",
       "  'it',\n",
       "  'aside',\n",
       "  ',',\n",
       "  'exposing',\n",
       "  'the',\n",
       "  'body',\n",
       "  'in',\n",
       "  'black',\n",
       "  'trousers',\n",
       "  'and',\n",
       "  'white',\n",
       "  'shirt',\n",
       "  '.'],\n",
       " ['At',\n",
       "  'that',\n",
       "  'instant',\n",
       "  'the',\n",
       "  'air',\n",
       "  'sprang',\n",
       "  'to',\n",
       "  'flame',\n",
       "  ',',\n",
       "  'a',\n",
       "  'cracking',\n",
       "  'shock',\n",
       "  'of',\n",
       "  'thunder',\n",
       "  'shook',\n",
       "  'the',\n",
       "  'stunned',\n",
       "  'world',\n",
       "  'and',\n",
       "  'Henry',\n",
       "  'Armstrong',\n",
       "  'tranquilly',\n",
       "  'sat',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'inarticulate',\n",
       "  'cries',\n",
       "  'the',\n",
       "  'men',\n",
       "  'fled',\n",
       "  'in',\n",
       "  'terror',\n",
       "  ',',\n",
       "  'each',\n",
       "  'in',\n",
       "  'a',\n",
       "  'different',\n",
       "  'direction',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'nothing',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'could',\n",
       "  'two',\n",
       "  'of',\n",
       "  'them',\n",
       "  'have',\n",
       "  'been',\n",
       "  'persuaded',\n",
       "  'to',\n",
       "  'return',\n",
       "  '.'],\n",
       " ['But', 'Jess', 'was', 'of', 'another', 'breed', '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'grey',\n",
       "  'of',\n",
       "  'the',\n",
       "  'morning',\n",
       "  'the',\n",
       "  'two',\n",
       "  'students',\n",
       "  ',',\n",
       "  'pallid',\n",
       "  'and',\n",
       "  'haggard',\n",
       "  'from',\n",
       "  'anxiety',\n",
       "  'and',\n",
       "  'with',\n",
       "  'the',\n",
       "  'terror',\n",
       "  'of',\n",
       "  'their',\n",
       "  'adventure',\n",
       "  'still',\n",
       "  'beating',\n",
       "  'tumultuously',\n",
       "  'in',\n",
       "  'their',\n",
       "  'blood',\n",
       "  ',',\n",
       "  'met',\n",
       "  'at',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'college',\n",
       "  '.'],\n",
       " [\"'You\", 'saw', 'it', '?', \"'\"],\n",
       " ['cried', 'one', '.'],\n",
       " [\"'God\", '!'],\n",
       " ['yes', '--', 'what', 'are', 'we', 'to', 'do', '?', \"'\"],\n",
       " ['They',\n",
       "  'went',\n",
       "  'around',\n",
       "  'to',\n",
       "  'the',\n",
       "  'rear',\n",
       "  'of',\n",
       "  'the',\n",
       "  'building',\n",
       "  ',',\n",
       "  'where',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'a',\n",
       "  'horse',\n",
       "  ',',\n",
       "  'attached',\n",
       "  'to',\n",
       "  'a',\n",
       "  'light',\n",
       "  'wagon',\n",
       "  ',',\n",
       "  'hitched',\n",
       "  'to',\n",
       "  'a',\n",
       "  'gatepost',\n",
       "  'near',\n",
       "  'the',\n",
       "  'door',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dissecting-room',\n",
       "  '.'],\n",
       " ['Mechanically', 'they', 'entered', 'the', 'room', '.'],\n",
       " ['On',\n",
       "  'a',\n",
       "  'bench',\n",
       "  'in',\n",
       "  'the',\n",
       "  'obscurity',\n",
       "  'sat',\n",
       "  'the',\n",
       "  'negro',\n",
       "  'Jess',\n",
       "  '.'],\n",
       " ['He', 'rose', ',', 'grinning', ',', 'all', 'eyes', 'and', 'teeth', '.'],\n",
       " [\"'\", 'I', \"'m\", 'waiting', 'for', 'my', 'pay', ',', \"'\", 'he', 'said', '.'],\n",
       " ['Stretched',\n",
       "  'naked',\n",
       "  'on',\n",
       "  'a',\n",
       "  'long',\n",
       "  'table',\n",
       "  'lay',\n",
       "  'the',\n",
       "  'body',\n",
       "  'of',\n",
       "  'Henry',\n",
       "  'Armstrong',\n",
       "  ',',\n",
       "  'the',\n",
       "  'head',\n",
       "  'defiled',\n",
       "  'with',\n",
       "  'blood',\n",
       "  'and',\n",
       "  'clay',\n",
       "  'from',\n",
       "  'a',\n",
       "  'blow',\n",
       "  'with',\n",
       "  'a',\n",
       "  'spade',\n",
       "  '.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = tokenize.sent_tokenize(text1)\n",
    "words = [tokenize.word_tokenize(sent) for sent in sentences]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DT'),\n",
       "  ('fact', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('Henry', 'NNP'),\n",
       "  ('Armstrong', 'NNP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('buried', 'VBN'),\n",
       "  ('did', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('seem', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('him', 'PRP'),\n",
       "  ('to', 'TO'),\n",
       "  ('prove', 'VB'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('dead', 'JJ'),\n",
       "  (':', ':'),\n",
       "  ('he', 'PRP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('always', 'RB'),\n",
       "  ('been', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('hard', 'JJ'),\n",
       "  ('man', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('convince', 'VB'),\n",
       "  ('.', '.')],\n",
       " [('That', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('was', 'VBD'),\n",
       "  ('buried', 'VBN'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('testimony', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('senses', 'NNS'),\n",
       "  ('compelled', 'VBD'),\n",
       "  ('him', 'PRP'),\n",
       "  ('to', 'TO'),\n",
       "  ('admit', 'VB'),\n",
       "  ('.', '.')],\n",
       " [('His', 'PRP$'),\n",
       "  ('posture', 'NN'),\n",
       "  ('--', ':'),\n",
       "  ('flat', 'JJ'),\n",
       "  ('upon', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('back', 'NN'),\n",
       "  (',', ','),\n",
       "  ('with', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('hands', 'NNS'),\n",
       "  ('crossed', 'VBN'),\n",
       "  ('upon', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('stomach', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('tied', 'VBN'),\n",
       "  ('with', 'IN'),\n",
       "  ('something', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('easily', 'RB'),\n",
       "  ('broke', 'VBD'),\n",
       "  ('without', 'IN'),\n",
       "  ('profitably', 'RB'),\n",
       "  ('altering', 'VBG'),\n",
       "  ('the', 'DT'),\n",
       "  ('situation', 'NN'),\n",
       "  ('--', ':'),\n",
       "  ('the', 'DT'),\n",
       "  ('strict', 'JJ'),\n",
       "  ('confinement', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('entire', 'JJ'),\n",
       "  ('person', 'NN'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('black', 'JJ'),\n",
       "  ('darkness', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('profound', 'NN'),\n",
       "  ('silence', 'NN'),\n",
       "  (',', ','),\n",
       "  ('made', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('body', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('evidence', 'NN'),\n",
       "  ('impossible', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('controvert', 'VB'),\n",
       "  ('and', 'CC'),\n",
       "  ('he', 'PRP'),\n",
       "  ('accepted', 'VBD'),\n",
       "  ('it', 'PRP'),\n",
       "  ('without', 'IN'),\n",
       "  ('cavil', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CC'),\n",
       "  ('dead', 'JJ'),\n",
       "  ('--', ':'),\n",
       "  ('no', 'DT'),\n",
       "  (';', ':'),\n",
       "  ('he', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('only', 'RB'),\n",
       "  ('very', 'RB'),\n",
       "  (',', ','),\n",
       "  ('very', 'RB'),\n",
       "  ('ill', 'RB'),\n",
       "  ('.', '.')],\n",
       " [('He', 'PRP'),\n",
       "  ('had', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('withal', 'NN'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('invalid', 'NN'),\n",
       "  (\"'s\", 'POS'),\n",
       "  ('apathy', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('did', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('greatly', 'RB'),\n",
       "  ('concern', 'NN'),\n",
       "  ('himself', 'PRP'),\n",
       "  ('about', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('uncommon', 'JJ'),\n",
       "  ('fate', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('had', 'VBD'),\n",
       "  ('been', 'VBN'),\n",
       "  ('allotted', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('him', 'PRP'),\n",
       "  ('.', '.')],\n",
       " [('No', 'DT'),\n",
       "  ('philosopher', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('he', 'PRP'),\n",
       "  ('--', ':'),\n",
       "  ('just', 'RB'),\n",
       "  ('a', 'DT'),\n",
       "  ('plain', 'NN'),\n",
       "  (',', ','),\n",
       "  ('commonplace', 'NN'),\n",
       "  ('person', 'NN'),\n",
       "  ('gifted', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('time', 'NN'),\n",
       "  ('being', 'VBG'),\n",
       "  (',', ','),\n",
       "  ('with', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('pathological', 'JJ'),\n",
       "  ('indifference', 'NN'),\n",
       "  (':', ':'),\n",
       "  ('the', 'DT'),\n",
       "  ('organ', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('feared', 'VBD'),\n",
       "  ('consequences', 'NNS'),\n",
       "  ('with', 'IN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('torpid', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('So', 'RB'),\n",
       "  (',', ','),\n",
       "  ('with', 'IN'),\n",
       "  ('no', 'DT'),\n",
       "  ('particular', 'JJ'),\n",
       "  ('apprehension', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('immediate', 'JJ'),\n",
       "  ('future', 'NN'),\n",
       "  (',', ','),\n",
       "  ('he', 'PRP'),\n",
       "  ('fell', 'VBD'),\n",
       "  ('asleep', 'RB'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'DT'),\n",
       "  ('was', 'VBD'),\n",
       "  ('peace', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('Henry', 'NNP'),\n",
       "  ('Armstrong', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CC'),\n",
       "  ('something', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('going', 'VBG'),\n",
       "  ('on', 'IN'),\n",
       "  ('overhead', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('It', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('dark', 'JJ'),\n",
       "  ('summer', 'NN'),\n",
       "  ('night', 'NN'),\n",
       "  (',', ','),\n",
       "  ('shot', 'VBN'),\n",
       "  ('through', 'IN'),\n",
       "  ('with', 'IN'),\n",
       "  ('infrequent', 'JJ'),\n",
       "  ('shimmers', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('lightning', 'VBG'),\n",
       "  ('silently', 'RB'),\n",
       "  ('firing', 'VBG'),\n",
       "  ('a', 'DT'),\n",
       "  ('cloud', 'JJ'),\n",
       "  ('lying', 'NN'),\n",
       "  ('low', 'JJ'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('west', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('portending', 'VBG'),\n",
       "  ('a', 'DT'),\n",
       "  ('storm', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('These', 'DT'),\n",
       "  ('brief', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('stammering', 'VBG'),\n",
       "  ('illuminations', 'NNS'),\n",
       "  ('brought', 'VBD'),\n",
       "  ('out', 'RP'),\n",
       "  ('with', 'IN'),\n",
       "  ('ghastly', 'RB'),\n",
       "  ('distinctness', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('monuments', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('headstones', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('cemetery', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('seemed', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('set', 'VB'),\n",
       "  ('them', 'PRP'),\n",
       "  ('dancing', 'VBG'),\n",
       "  ('.', '.')],\n",
       " [('It', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('a', 'DT'),\n",
       "  ('night', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('any', 'DT'),\n",
       "  ('credible', 'JJ'),\n",
       "  ('witness', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('likely', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('be', 'VB'),\n",
       "  ('straying', 'VBG'),\n",
       "  ('about', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('cemetery', 'NN'),\n",
       "  (',', ','),\n",
       "  ('so', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('three', 'CD'),\n",
       "  ('men', 'NNS'),\n",
       "  ('who', 'WP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('there', 'RB'),\n",
       "  (',', ','),\n",
       "  ('digging', 'VBG'),\n",
       "  ('into', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('grave', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Henry', 'NNP'),\n",
       "  ('Armstrong', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('felt', 'VBD'),\n",
       "  ('reasonably', 'RB'),\n",
       "  ('secure', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Two', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('them', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('young', 'JJ'),\n",
       "  ('students', 'NNS'),\n",
       "  ('from', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('medical', 'JJ'),\n",
       "  ('college', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('few', 'JJ'),\n",
       "  ('miles', 'NNS'),\n",
       "  ('away', 'RB'),\n",
       "  (';', ':'),\n",
       "  ('the', 'DT'),\n",
       "  ('third', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('gigantic', 'JJ'),\n",
       "  ('negro', 'NN'),\n",
       "  ('known', 'VBN'),\n",
       "  ('as', 'IN'),\n",
       "  ('Jess', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('For', 'IN'),\n",
       "  ('many', 'JJ'),\n",
       "  ('years', 'NNS'),\n",
       "  ('Jess', 'NNP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('been', 'VBN'),\n",
       "  ('employed', 'VBN'),\n",
       "  ('about', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('cemetery', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('man-of-all-work', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('favourite', 'JJ'),\n",
       "  ('pleasantry', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('knew', 'VBD'),\n",
       "  (\"'every\", 'JJ'),\n",
       "  ('soul', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('place', 'NN'),\n",
       "  ('.', '.'),\n",
       "  (\"'\", \"''\")],\n",
       " [('From', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('nature', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('what', 'WP'),\n",
       "  ('he', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('now', 'RB'),\n",
       "  ('doing', 'VBG'),\n",
       "  ('it', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('inferable', 'JJ'),\n",
       "  ('that', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('place', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('so', 'RB'),\n",
       "  ('populous', 'JJ'),\n",
       "  ('as', 'IN'),\n",
       "  ('its', 'PRP$'),\n",
       "  ('register', 'NN'),\n",
       "  ('may', 'MD'),\n",
       "  ('have', 'VB'),\n",
       "  ('shown', 'VBN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('to', 'TO'),\n",
       "  ('be', 'VB'),\n",
       "  ('.', '.')],\n",
       " [('Outside', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('wall', 'NN'),\n",
       "  (',', ','),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('part', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('grounds', 'NNS'),\n",
       "  ('farthest', 'VBP'),\n",
       "  ('from', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('public', 'JJ'),\n",
       "  ('road', 'NN'),\n",
       "  (',', ','),\n",
       "  ('were', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('horse', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('a', 'DT'),\n",
       "  ('light', 'JJ'),\n",
       "  ('wagon', 'NN'),\n",
       "  (',', ','),\n",
       "  ('waiting', 'VBG'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('work', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('excavation', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('difficult', 'JJ'),\n",
       "  (':', ':'),\n",
       "  ('the', 'DT'),\n",
       "  ('earth', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('grave', 'NN'),\n",
       "  ('had', 'VBD'),\n",
       "  ('been', 'VBN'),\n",
       "  ('loosely', 'RB'),\n",
       "  ('filled', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('few', 'JJ'),\n",
       "  ('hours', 'NNS'),\n",
       "  ('before', 'IN'),\n",
       "  ('offered', 'VBN'),\n",
       "  ('little', 'JJ'),\n",
       "  ('resistance', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('was', 'VBD'),\n",
       "  ('soon', 'RB'),\n",
       "  ('thrown', 'VBN'),\n",
       "  ('out', 'RP'),\n",
       "  ('.', '.')],\n",
       " [('Removal', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('casket', 'NN'),\n",
       "  ('from', 'IN'),\n",
       "  ('its', 'PRP$'),\n",
       "  ('box', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('less', 'JJR'),\n",
       "  ('easy', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('but', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('taken', 'VBN'),\n",
       "  ('out', 'RP'),\n",
       "  (',', ','),\n",
       "  ('for', 'IN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('perquisite', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Jess', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('who', 'WP'),\n",
       "  ('carefully', 'RB'),\n",
       "  ('unscrewed', 'VBD'),\n",
       "  ('the', 'DT'),\n",
       "  ('cover', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('laid', 'VBD'),\n",
       "  ('it', 'PRP'),\n",
       "  ('aside', 'RB'),\n",
       "  (',', ','),\n",
       "  ('exposing', 'VBG'),\n",
       "  ('the', 'DT'),\n",
       "  ('body', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('black', 'JJ'),\n",
       "  ('trousers', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('white', 'JJ'),\n",
       "  ('shirt', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('At', 'IN'),\n",
       "  ('that', 'DT'),\n",
       "  ('instant', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('air', 'NN'),\n",
       "  ('sprang', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('flame', 'VB'),\n",
       "  (',', ','),\n",
       "  ('a', 'DT'),\n",
       "  ('cracking', 'VBG'),\n",
       "  ('shock', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('thunder', 'NN'),\n",
       "  ('shook', 'VBD'),\n",
       "  ('the', 'DT'),\n",
       "  ('stunned', 'JJ'),\n",
       "  ('world', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('Henry', 'NNP'),\n",
       "  ('Armstrong', 'NNP'),\n",
       "  ('tranquilly', 'RB'),\n",
       "  ('sat', 'VBD'),\n",
       "  ('up', 'RP'),\n",
       "  ('.', '.')],\n",
       " [('With', 'IN'),\n",
       "  ('inarticulate', 'JJ'),\n",
       "  ('cries', 'NNS'),\n",
       "  ('the', 'DT'),\n",
       "  ('men', 'NNS'),\n",
       "  ('fled', 'VBD'),\n",
       "  ('in', 'IN'),\n",
       "  ('terror', 'NN'),\n",
       "  (',', ','),\n",
       "  ('each', 'DT'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('different', 'JJ'),\n",
       "  ('direction', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('For', 'IN'),\n",
       "  ('nothing', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('earth', 'NN'),\n",
       "  ('could', 'MD'),\n",
       "  ('two', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('them', 'PRP'),\n",
       "  ('have', 'VBP'),\n",
       "  ('been', 'VBN'),\n",
       "  ('persuaded', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('return', 'VB'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CC'),\n",
       "  ('Jess', 'NNP'),\n",
       "  ('was', 'VBD'),\n",
       "  ('of', 'IN'),\n",
       "  ('another', 'DT'),\n",
       "  ('breed', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('In', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('grey', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('morning', 'NN'),\n",
       "  ('the', 'DT'),\n",
       "  ('two', 'CD'),\n",
       "  ('students', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('pallid', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('haggard', 'NN'),\n",
       "  ('from', 'IN'),\n",
       "  ('anxiety', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('with', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('terror', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('adventure', 'NN'),\n",
       "  ('still', 'RB'),\n",
       "  ('beating', 'VBG'),\n",
       "  ('tumultuously', 'RB'),\n",
       "  ('in', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('blood', 'NN'),\n",
       "  (',', ','),\n",
       "  ('met', 'VBD'),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('medical', 'JJ'),\n",
       "  ('college', 'NN'),\n",
       "  ('.', '.')],\n",
       " [(\"'You\", 'CD'), ('saw', 'VBD'), ('it', 'PRP'), ('?', '.'), (\"'\", \"''\")],\n",
       " [('cried', 'JJ'), ('one', 'CD'), ('.', '.')],\n",
       " [(\"'God\", 'CD'), ('!', '.')],\n",
       " [('yes', 'RB'),\n",
       "  ('--', ':'),\n",
       "  ('what', 'WP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('we', 'PRP'),\n",
       "  ('to', 'TO'),\n",
       "  ('do', 'VB'),\n",
       "  ('?', '.'),\n",
       "  (\"'\", \"''\")],\n",
       " [('They', 'PRP'),\n",
       "  ('went', 'VBD'),\n",
       "  ('around', 'IN'),\n",
       "  ('to', 'TO'),\n",
       "  ('the', 'DT'),\n",
       "  ('rear', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('building', 'NN'),\n",
       "  (',', ','),\n",
       "  ('where', 'WRB'),\n",
       "  ('they', 'PRP'),\n",
       "  ('saw', 'VBD'),\n",
       "  ('a', 'DT'),\n",
       "  ('horse', 'NN'),\n",
       "  (',', ','),\n",
       "  ('attached', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('a', 'DT'),\n",
       "  ('light', 'JJ'),\n",
       "  ('wagon', 'NN'),\n",
       "  (',', ','),\n",
       "  ('hitched', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('a', 'DT'),\n",
       "  ('gatepost', 'NN'),\n",
       "  ('near', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('door', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('dissecting-room', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Mechanically', 'RB'),\n",
       "  ('they', 'PRP'),\n",
       "  ('entered', 'VBD'),\n",
       "  ('the', 'DT'),\n",
       "  ('room', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('On', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('bench', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('obscurity', 'NN'),\n",
       "  ('sat', 'VBD'),\n",
       "  ('the', 'DT'),\n",
       "  ('negro', 'JJ'),\n",
       "  ('Jess', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('He', 'PRP'),\n",
       "  ('rose', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('grinning', 'VBG'),\n",
       "  (',', ','),\n",
       "  ('all', 'DT'),\n",
       "  ('eyes', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('teeth', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [(\"'\", 'POS'),\n",
       "  ('I', 'PRP'),\n",
       "  (\"'m\", 'VBP'),\n",
       "  ('waiting', 'VBG'),\n",
       "  ('for', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('pay', 'NN'),\n",
       "  (',', ','),\n",
       "  (\"'\", \"''\"),\n",
       "  ('he', 'PRP'),\n",
       "  ('said', 'VBD'),\n",
       "  ('.', '.')],\n",
       " [('Stretched', 'VBN'),\n",
       "  ('naked', 'VBN'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('long', 'JJ'),\n",
       "  ('table', 'JJ'),\n",
       "  ('lay', 'VBD'),\n",
       "  ('the', 'DT'),\n",
       "  ('body', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Henry', 'NNP'),\n",
       "  ('Armstrong', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('head', 'NN'),\n",
       "  ('defiled', 'VBD'),\n",
       "  ('with', 'IN'),\n",
       "  ('blood', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('clay', 'NN'),\n",
       "  ('from', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('blow', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('spade', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tags = [nltk.pos_tag(sent) for sent in words]\n",
    "word_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pos_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henry</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armstrong</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>blow</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>spade</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Pos_Tag\n",
       "0          The      DT\n",
       "1         fact      NN\n",
       "2         that      IN\n",
       "3        Henry     NNP\n",
       "4    Armstrong     NNP\n",
       "..         ...     ...\n",
       "690       blow      NN\n",
       "691       with      IN\n",
       "692          a      DT\n",
       "693      spade      NN\n",
       "694          .       .\n",
       "\n",
       "[695 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=[]\n",
    "pos=[]\n",
    "for idx in word_tags:\n",
    "    for idj in idx:\n",
    "        word.append(idj[0])\n",
    "\n",
    "for idx in word_tags:\n",
    "    for idj in idx:\n",
    "        pos.append(idj[1])\n",
    "\n",
    "frame={'Word':word,\n",
    "       'Pos_Tag':pos}\n",
    "frame = pd.DataFrame(frame)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame[[\"Word\", \"Pos_Tag\"]]\n",
    "\n",
    "\n",
    "X_words = word_vectorizer.transform(X[\"Word\"])\n",
    "\n",
    "\n",
    "X_pos = pos_vectorizer.transform(X[\"Pos_Tag\"])\n",
    "X_combined = pd.concat(\n",
    "    [pd.DataFrame(X_words.toarray()), pd.DataFrame(X_pos.toarray())], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PERSON', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'CARDINAL',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'CARDINAL', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'CARDINAL', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'O'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = dic_models['SVC']\n",
    "text_pred = classifier.predict(X_combined)\n",
    "\n",
    "display(text_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'fact', 'that', 'Henry', 'Armstrong', 'was', 'buried', 'did', 'not', 'seem', 'to', 'him', 'to', 'prove', 'that', 'he', 'was', 'dead', ':', 'he', 'had', 'always', 'been', 'a', 'hard', 'man', 'to', 'convince', '.', 'That', 'he', 'really', 'was', 'buried', ',', 'the', 'testimony', 'of', 'his', 'senses', 'compelled', 'him', 'to', 'admit', '.', 'His', 'posture', '--', 'flat', 'upon', 'his', 'back', ',', 'with', 'his', 'hands', 'crossed', 'upon', 'his', 'stomach', 'and', 'tied', 'with', 'something', 'that', 'he', 'easily', 'broke', 'without', 'profitably', 'altering', 'the', 'situation', '--', 'the', 'strict', 'confinement', 'of', 'his', 'entire', 'person', ',', 'the', 'black', 'darkness', 'and', 'profound', 'silence', ',', 'made', 'a', 'body', 'of', 'evidence', 'impossible', 'to', 'controvert', 'and', 'he', 'accepted', 'it', 'without', 'cavil', '.', 'But', 'dead', '--', 'no', ';', 'he', 'was', 'only', 'very', ',', 'very', 'ill', '.', 'He', 'had', ',', 'withal', ',', 'the', 'invalid', \"'s\", 'apathy', 'and', 'did', 'not', 'greatly', 'concern', 'himself', 'about', 'the', 'uncommon', 'fate', 'that', 'had', 'been', 'allotted', 'to', 'him', '.', 'No', 'philosopher', 'was', 'he', '--', 'just', 'a', 'plain', ',', 'commonplace', 'person', 'gifted', ',', 'for', 'the', 'time', 'being', ',', 'with', 'a', 'pathological', 'indifference', ':', 'the', 'organ', 'that', 'he', 'feared', 'consequences', 'with', 'was', 'torpid', '.', 'So', ',', 'with', 'no', 'particular', 'apprehension', 'for', 'his', 'immediate', 'future', ',', 'he', 'fell', 'asleep', 'and', 'all', 'was', 'peace', 'with', 'Henry', 'Armstrong', '.', 'But', 'something', 'was', 'going', 'on', 'overhead', '.', 'It', 'was', 'a', 'dark', 'summer', 'night', ',', 'shot', 'through', 'with', 'infrequent', 'shimmers', 'of', 'lightning', 'silently', 'firing', 'a', 'cloud', 'lying', 'low', 'in', 'the', 'west', 'and', 'portending', 'a', 'storm', '.', 'These', 'brief', ',', 'stammering', 'illuminations', 'brought', 'out', 'with', 'ghastly', 'distinctness', 'the', 'monuments', 'and', 'headstones', 'of', 'the', 'cemetery', 'and', 'seemed', 'to', 'set', 'them', 'dancing', '.', 'It', 'was', 'not', 'a', 'night', 'in', 'which', 'any', 'credible', 'witness', 'was', 'likely', 'to', 'be', 'straying', 'about', 'a', 'cemetery', ',', 'so', 'the', 'three', 'men', 'who', 'were', 'there', ',', 'digging', 'into', 'the', 'grave', 'of', 'Henry', 'Armstrong', ',', 'felt', 'reasonably', 'secure', '.', 'Two', 'of', 'them', 'were', 'young', 'students', 'from', 'a', 'medical', 'college', 'a', 'few', 'miles', 'away', ';', 'the', 'third', 'was', 'a', 'gigantic', 'negro', 'known', 'as', 'Jess', '.', 'For', 'many', 'years', 'Jess', 'had', 'been', 'employed', 'about', 'the', 'cemetery', 'as', 'a', 'man-of-all-work', 'and', 'it', 'was', 'his', 'favourite', 'pleasantry', 'that', 'he', 'knew', \"'every\", 'soul', 'in', 'the', 'place', '.', \"'\", 'From', 'the', 'nature', 'of', 'what', 'he', 'was', 'now', 'doing', 'it', 'was', 'inferable', 'that', 'the', 'place', 'was', 'not', 'so', 'populous', 'as', 'its', 'register', 'may', 'have', 'shown', 'it', 'to', 'be', '.', 'Outside', 'the', 'wall', ',', 'at', 'the', 'part', 'of', 'the', 'grounds', 'farthest', 'from', 'the', 'public', 'road', ',', 'were', 'a', 'horse', 'and', 'a', 'light', 'wagon', ',', 'waiting', '.', 'The', 'work', 'of', 'excavation', 'was', 'not', 'difficult', ':', 'the', 'earth', 'with', 'which', 'the', 'grave', 'had', 'been', 'loosely', 'filled', 'a', 'few', 'hours', 'before', 'offered', 'little', 'resistance', 'and', 'was', 'soon', 'thrown', 'out', '.', 'Removal', 'of', 'the', 'casket', 'from', 'its', 'box', 'was', 'less', 'easy', ',', 'but', 'it', 'was', 'taken', 'out', ',', 'for', 'it', 'was', 'a', 'perquisite', 'of', 'Jess', ',', 'who', 'carefully', 'unscrewed', 'the', 'cover', 'and', 'laid', 'it', 'aside', ',', 'exposing', 'the', 'body', 'in', 'black', 'trousers', 'and', 'white', 'shirt', '.', 'At', 'that', 'instant', 'the', 'air', 'sprang', 'to', 'flame', ',', 'a', 'cracking', 'shock', 'of', 'thunder', 'shook', 'the', 'stunned', 'world', 'and', 'Henry', 'Armstrong', 'tranquilly', 'sat', 'up', '.', 'With', 'inarticulate', 'cries', 'the', 'men', 'fled', 'in', 'terror', ',', 'each', 'in', 'a', 'different', 'direction', '.', 'For', 'nothing', 'on', 'earth', 'could', 'two', 'of', 'them', 'have', 'been', 'persuaded', 'to', 'return', '.', 'But', 'Jess', 'was', 'of', 'another', 'breed', '.', 'In', 'the', 'grey', 'of', 'the', 'morning', 'the', 'two', 'students', ',', 'pallid', 'and', 'haggard', 'from', 'anxiety', 'and', 'with', 'the', 'terror', 'of', 'their', 'adventure', 'still', 'beating', 'tumultuously', 'in', 'their', 'blood', ',', 'met', 'at', 'the', 'medical', 'college', '.', \"'You\", 'saw', 'it', '?', \"'\", 'cried', 'one', '.', \"'God\", '!', 'yes', '--', 'what', 'are', 'we', 'to', 'do', '?', \"'\", 'They', 'went', 'around', 'to', 'the', 'rear', 'of', 'the', 'building', ',', 'where', 'they', 'saw', 'a', 'horse', ',', 'attached', 'to', 'a', 'light', 'wagon', ',', 'hitched', 'to', 'a', 'gatepost', 'near', 'the', 'door', 'of', 'the', 'dissecting-room', '.', 'Mechanically', 'they', 'entered', 'the', 'room', '.', 'On', 'a', 'bench', 'in', 'the', 'obscurity', 'sat', 'the', 'negro', 'Jess', '.', 'He', 'rose', ',', 'grinning', ',', 'all', 'eyes', 'and', 'teeth', '.', \"'\", 'I', \"'m\", 'waiting', 'for', 'my', 'pay', ',', \"'\", 'he', 'said', '.', 'Stretched', 'naked', 'on', 'a', 'long', 'table', 'lay', 'the', 'body', 'of', 'Henry', 'Armstrong', ',', 'the', 'head', 'defiled', 'with', 'blood', 'and', 'clay', 'from', 'a', 'blow', 'with', 'a', 'spade', '.']\n",
      "695\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "word = list(frame.Word)\n",
    "print(word)\n",
    "print(len(word))\n",
    "print(len(text_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry: PERSON\n",
      "Henry: PERSON\n",
      "Henry: PERSON\n",
      "Two: CARDINAL\n",
      "Henry: PERSON\n",
      "two: CARDINAL\n",
      "two: CARDINAL\n",
      "'You: CARDINAL\n",
      "'God: CARDINAL\n",
      "Henry: PERSON\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(text_pred)):\n",
    "      if text_pred[idx] == \"O\":\n",
    "            continue\n",
    "            \n",
    "      elif text_pred[idx] == \"PERSON\":\n",
    "            print(f\"{word[idx]}: PERSON\")\n",
    "      elif text_pred[idx] == \"DATE\":\n",
    "            print(f\"{word[idx]}: DATE\")  \n",
    "      elif text_pred[idx] == \"P-NUMBER\":\n",
    "            print(f\"{word[idx]}: P-NUMBER\")  \n",
    "      elif text_pred[idx] == \"CARDINAL\":\n",
    "            print(f\"{word[idx]}: CARDINAL\")\n",
    "      elif text_pred[idx] == \"COMPANY\":\n",
    "            print(f\"{word[idx]}: COMPANY\")\n",
    "      elif text_pred[idx] == \"ORG\":\n",
    "            print(f\"{word[idx]}: ORG\")\n",
    "      elif text_pred[idx] == \"COLOR\":\n",
    "            print(f\"{word[idx]}: COLOR\")\n",
    "      elif text_pred[idx] == \"Org\":\n",
    "            print(f\"{word[idx]}: Org\")\n",
    "      elif text_pred[idx] == \"CITY\":\n",
    "            print(f\"{word[idx]}: CITY\")\n",
    "      elif text_pred[idx] == \"COUNTRY\":\n",
    "            print(f\"{word[idx]}: COUNTRY\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlp_Classifier.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load     # save model\n",
    "model = dic_models['mlp_Classifier']\n",
    "dump(model,\"mlp_Classifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load('mlp_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "model_loaded = load(\"mlp_Classifier.joblib\")\n",
    "st.sidebar.header(\"Name Entity Recognition Task: \")\n",
    "\n",
    "text = st.sidebar.text_area(\"Enter Your Text:\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    words = [tokenize.word_tokenize(sent) for sent in sentences]\n",
    "    word_tags = [nltk.pos_tag(sent) for sent in words]\n",
    "    \n",
    "    word=[]\n",
    "    pos=[]\n",
    "    for idx in word_tags:\n",
    "        for idj in idx:\n",
    "            word.append(idj[0])\n",
    "\n",
    "    for idx in word_tags:\n",
    "        for idj in idx:\n",
    "            pos.append(idj[1])\n",
    "\n",
    "    frame={'Word':word,\n",
    "        'Pos_Tag':pos}\n",
    "    frame = pd.DataFrame(frame)\n",
    "    X = frame[[\"Word\", \"Pos_Tag\"]]\n",
    "    \n",
    "    with open('word_vectorizer.pkl', 'rb') as f:\n",
    "        word_vectorizer = pickle.load(f)\n",
    "\n",
    "    with open('pos_vectorizer.pkl', 'rb') as f:\n",
    "        pos_vectorizer = pickle.load(f)\n",
    "        \n",
    "    X_words = word_vectorizer.transform(X[\"Word\"])\n",
    "\n",
    "    X_pos = pos_vectorizer.transform(X[\"Pos_Tag\"])\n",
    "    X_combined = pd.concat(\n",
    "        [pd.DataFrame(X_words.toarray()), pd.DataFrame(X_pos.toarray())], axis=1\n",
    "    )\n",
    "    \n",
    "    return [ X_combined , frame.Word] \n",
    "\n",
    "if text:\n",
    "   Text_Features , word = preprocess_text(text)\n",
    "   word = list(word)\n",
    "   text_pred = model_loaded.predict(Text_Features)\n",
    "   \n",
    "   st.header(\"The Result:\")\n",
    "   \n",
    "   for idx in range(len(text_pred)):\n",
    "      if text_pred[idx] == \"O\":\n",
    "            continue\n",
    "            # print (f\"{word[idx]}: O\") \n",
    "      elif text_pred[idx] == \"PERSON\":\n",
    "            st.write(f\"{word[idx]}: PERSON\")\n",
    "      elif text_pred[idx] == \"DATE\":\n",
    "            st.write(f\"{word[idx]}: DATE\")  \n",
    "      elif text_pred[idx] == \"P-NUMBER\":\n",
    "            st.write(f\"{word[idx]}: P-NUMBER\")  \n",
    "      elif text_pred[idx] == \"CARDINAL\":\n",
    "            st.write(f\"{word[idx]}: CARDINAL\")\n",
    "      elif text_pred[idx] == \"COMPANY\":\n",
    "            st.write(f\"{word[idx]}: COMPANY\")\n",
    "      elif text_pred[idx] == \"ORG\":\n",
    "            st.write(f\"{word[idx]}: ORG\")\n",
    "      elif text_pred[idx] == \"COLOR\":\n",
    "            st.write(f\"{word[idx]}: COLOR\")\n",
    "      elif text_pred[idx] == \"Org\":\n",
    "            st.write(f\"{word[idx]}: Org\")\n",
    "      elif text_pred[idx] == \"CITY\":\n",
    "            st.write(f\"{word[idx]}: CITY\")\n",
    "      elif text_pred[idx] == \"COUNTRY\":\n",
    "            st.write(f\"{word[idx]}: COUNTRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
